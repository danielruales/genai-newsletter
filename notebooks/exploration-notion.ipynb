{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Access keys and configurations\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv('ANTHROPIC_API_KEY')\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY') # OpenAI API key\n",
    "os.environ[\"NOTION_API_KEY\"]=os.getenv('NOTION_API_KEY')\n",
    "os.environ[\"LIBRARY_DATABASE_ID\"]=os.getenv('LIBRARY_DATABASE_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vars = [\n",
    "    'LANGCHAIN_API_KEY',\n",
    "    'ANTHROPIC_API_KEY',\n",
    "    'NOTION_API_KEY',\n",
    "    'LIBRARY_DATABASE_ID'\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_vars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date():\n",
    "    # Get the current date\n",
    "    current_date = datetime.now()\n",
    "    # Format the date as YYYY-MM-DD\n",
    "    formatted_date = current_date.strftime('%Y-%m-%d')\n",
    "    return formatted_date\n",
    "\n",
    "print(get_current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "llm.invoke(\"Hello, world!\").content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notion_client import Client\n",
    "\n",
    "# Initialize the Notion client with your integration token\n",
    "notion = Client(auth=os.environ[\"NOTION_API_KEY\"])\n",
    "\n",
    "# Specify your database ID (the part of the URL after /<workspace>/)\n",
    "database_id = os.environ[\"LIBRARY_DATABASE_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the database\n",
    "response = notion.databases.query(\n",
    "    database_id=database_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_content(blocks):\n",
    "    \"\"\"Extract text content from page blocks.\"\"\"\n",
    "    content = []\n",
    "    for block in blocks['results']:\n",
    "        if block['type'] == 'paragraph':\n",
    "            print('paragraph')\n",
    "            try:\n",
    "                text = block['paragraph']['rich_text']\n",
    "                if text:\n",
    "                    content.append(text[0]['plain_text'])\n",
    "            except:\n",
    "                continue\n",
    "        elif block['type'] == 'heading_1':\n",
    "            print('heading_1')\n",
    "            try:\n",
    "                text = block['heading_1']['rich_text']\n",
    "                if text:\n",
    "                    content.append(f\"# {text[0]['plain_text']}\")\n",
    "            except:\n",
    "                continue\n",
    "        elif block['type'] == 'heading_2':\n",
    "            print('heading_2')\n",
    "            try:\n",
    "                text = block['heading_2']['rich_text']\n",
    "                if text:\n",
    "                    content.append(f\"## {text[0]['plain_text']}\")\n",
    "            except:\n",
    "                continue\n",
    "        elif block['type'] == 'bulleted_list_item':\n",
    "            print('bulleted_list_item')\n",
    "            try:\n",
    "                text = block['bulleted_list_item']['rich_text']\n",
    "                if text:\n",
    "                    content.append(f\"• {text[0]['plain_text']}\")\n",
    "            except:\n",
    "                continue\n",
    "    return '\\n'.join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the results (summary, titles, etc.)\n",
    "all_content = '<CONTEXT>'\n",
    "id = 1\n",
    "for page in response['results']:\n",
    "    page_id = page['id']\n",
    "    title = page['properties']['Name']['title'][0]['text']['content']\n",
    "    summary = page['properties']['AI summary']['rich_text'][0]['text']['content']\n",
    "    # print(id,title)\n",
    "    \n",
    "    page_content = notion.blocks.children.list(block_id=page_id)\n",
    "    extracted_content = extract_page_content(page_content)\n",
    "    \n",
    "    content = '\\n<Article Number: ' + str(id) + '>\\n' + 'Title: ' + title + '\\n' + 'Content: ' + extracted_content + '\\n</Article Number: ' + str(id) + '>'\n",
    "    all_content += content\n",
    "    \n",
    "    id += 1\n",
    "all_content += '\\n</CONTEXT>\\n--------------------\\n'\n",
    "\n",
    "print(all_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_prompt_newsletter = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=all_content + \"<START USER PROMPT>\\nProvide a weekly newsletter from the context provided. Use the context as a reference to what the user knows, but use outside sources to provide more information as needed.<END USER PROMPT>\"\n",
    ")\n",
    "\n",
    "chain = structured_prompt_newsletter | llm\n",
    "print(chain.invoke({\"topic\": \"evals\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-shot example template\n",
    "NEWSLETTER_EXAMPLE = \"\"\"\n",
    "Subject: AI & Tech Weekly Summary {date}\n",
    "\n",
    "Welcome to this week's AI & Tech digest! Here's what's making waves:\n",
    "\n",
    "Featured Story: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies. Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Industry Updates:\n",
    "• Google announced their latest quantum computing milestone\n",
    "• OpenAI released updates to their fine-tuning API\n",
    "• Meta's PyTorch 2.0 shows promising performance gains\n",
    "\n",
    "Must-Read Resources:\n",
    "• New paper on efficient training methods [link]\n",
    "• Updated documentation for PyTorch 2.0 [link]\n",
    "• Comprehensive guide to quantum computing basics [link]\n",
    "\n",
    "Join us next week for more updates!\n",
    "-------------------\n",
    "\"\"\".format(date=get_current_date())\n",
    "\n",
    "newsletter_example_formatted = \"\"\"<OUTPUT EXAMPLE>\n",
    "{example}\n",
    "</OUTPUT EXAMPLE>\n",
    "\"\"\".format(example=NEWSLETTER_EXAMPLE)\n",
    "\n",
    "newsletter_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"today_date\"],\n",
    "    template= newsletter_example_formatted + \"\"\"{context}\n",
    "\n",
    "Generate today's newsletter that follows the output example format while incorporating the key points from the provided context. Make sure to have at least three bullet points in each section. Add relevant sections as needed, but maintain the professional and engaging tone.\n",
    "Make sure to use today's date, {today_date}, in the subject line.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the chain\n",
    "chain = newsletter_prompt | llm\n",
    "# Test the chain\n",
    "newsletter = chain.invoke({\"context\": all_content, \"today_date\": get_current_date()})\n",
    "print(newsletter.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
