{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Access keys and configurations\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv('ANTHROPIC_API_KEY')\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY') # OpenAI API key\n",
    "os.environ[\"NOTION_API_KEY\"]=os.getenv('NOTION_API_KEY')\n",
    "os.environ[\"LIBRARY_DATABASE_ID\"]=os.getenv('LIBRARY_DATABASE_ID')\n",
    "os.environ[\"NEON_DATABASE_URL\"] = os.getenv(\"NEON_DATABASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# engine = create_engine(NEON_DATABASE_URL)\n",
    "engine = create_engine(os.environ[\"NEON_DATABASE_URL\"])\n",
    "\n",
    "def run_neon_query(query):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vars = [\n",
    "    'LANGCHAIN_API_KEY',\n",
    "    'ANTHROPIC_API_KEY',\n",
    "    'LIBRARY_DATABASE_ID',\n",
    "    'NEON_DATABASE_URL'\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_vars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date():\n",
    "    # Get the current date\n",
    "    current_date = datetime.now()\n",
    "    # Format the date as YYYY-MM-DD\n",
    "    formatted_date = current_date.strftime('%Y-%m-%d')\n",
    "    return formatted_date\n",
    "\n",
    "print(get_current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the LLM providers\n",
    "from langchain_openai import ChatOpenAI # OpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # Google\n",
    "from langchain_anthropic import ChatAnthropic # Anthropic\n",
    "\n",
    "# Importing the prompt template and chains\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Importing gradio for the UI\n",
    "import gradio as gr\n",
    "\n",
    "# Importing LangSmith for tracing\n",
    "from langsmith import Client\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "\n",
    "# Initialize LangSmith client\n",
    "langsmith_client = Client()\n",
    "\n",
    "# Initialize LangSmith tracer\n",
    "tracer = LangChainTracer(project_name=os.getenv('LANGCHAIN_PROJECT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_model_costs(config_path=\"../config/model_costs.json\"):\n",
    "    try:\n",
    "        with open(Path(config_path)) as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Model costs file not found at {config_path}\")\n",
    "\n",
    "# Load the costs\n",
    "MODEL_COSTS = load_model_costs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "model_name = \"claude-3-5-sonnet-20241022\"\n",
    "# model_name = \"gpt-4o-mini\"\n",
    "streaming = True # Streaming is when the LLM returns a token at a time, instead of the entire response at once\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatAnthropic(\n",
    "    model=model_name,\n",
    "    max_tokens=4096,\n",
    "    temperature=0.3,\n",
    "    streaming=streaming,\n",
    "    tags=[\"newsletter\"],\n",
    "    metadata={\n",
    "        \"ls_provider\": \"anthropic\",\n",
    "        \"ls_model_name\": model_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"model_cost_per_1k_input_tokens\": MODEL_COSTS[model_name][\"input\"],   # price per 1K input tokens\n",
    "        \"model_cost_per_1k_output_tokens\": MODEL_COSTS[model_name][\"output\"]    # price per 1K output tokens\n",
    "    }\n",
    ")\n",
    "\n",
    "# llm.invoke(\"Hello, world!\").content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_sql_query(filename):\n",
    "    query_path = Path(\"../queries\") / filename\n",
    "    with open(query_path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = load_sql_query(\"web_pages.sql\")\n",
    "df = run_neon_query(query)\n",
    "\n",
    "print(\"Number of rows:\", len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content_from_df(df):\n",
    "    \"\"\"Convert dataframe rows into formatted content string.\"\"\"\n",
    "    all_content = '<START CONTEXT>\\n'\n",
    "    all_content_list=[]\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Format each article with consistent structure\n",
    "        content = f\"\"\"\n",
    "<START Article Number: {idx + 1}>\n",
    "Title: {row['title']}\n",
    "URL: {row['url']}\n",
    "Summary: {row['summary']}\n",
    "Description: {row['description']}\n",
    "Created: {row['created_at'].strftime('%Y-%m-%d')}\n",
    "Type: {row['media_type']}\n",
    "<END Article Number: {idx + 1}>\n",
    "\"\"\"\n",
    "        # print('HERE***********', all_content_list)\n",
    "        all_content += content\n",
    "        all_content_list.append(content)\n",
    "    \n",
    "    all_content += '\\n<END CONTEXT>\\n--------------------\\n'\n",
    "    \n",
    "    return all_content, all_content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the results (summary, titles, etc.)\n",
    "all_content, all_content_list = create_content_from_df(df)\n",
    "\n",
    "print(len(all_content_list))\n",
    "print(all_content_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-shot example template\n",
    "NEWSLETTER_EXAMPLE = \"\"\"\n",
    "Subject: AI & Tech Weekly Summary {date}\n",
    "\n",
    "Welcome to this week's AI & Tech digest! Here's what's making waves:\n",
    "\n",
    "Featured Story #1: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies.\n",
    "Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Featured Story #2: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies.\n",
    "Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Featured Story #3: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies.\n",
    "Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Industry Updates:\n",
    "• Google announced their latest quantum computing milestone\n",
    "• OpenAI released updates to their fine-tuning API\n",
    "• Meta's PyTorch 2.0 shows promising performance gains\n",
    "\n",
    "Key Takeaways:\n",
    "• The future of AI is in smaller, more efficient models\n",
    "• Quantum computing is making significant strides\n",
    "• Fine-tuning APIs are becoming more powerful\n",
    "\n",
    "Must-Read Resources:\n",
    "• New paper on efficient training methods [link]\n",
    "• Updated documentation for PyTorch 2.0 [link]\n",
    "• Comprehensive guide to quantum computing basics [link]\n",
    "\n",
    "Join us next week for more updates!\n",
    "-------------------\n",
    "\"\"\".format(date=get_current_date())\n",
    "\n",
    "newsletter_example_formatted = \"\"\"<OUTPUT EXAMPLE>\n",
    "{example}\n",
    "</OUTPUT EXAMPLE>\n",
    "\"\"\".format(example=NEWSLETTER_EXAMPLE)\n",
    "\n",
    "newsletter_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"today_date\"],\n",
    "    template= newsletter_example_formatted + \"\"\"{context}\n",
    "\n",
    "Generate today's newsletter that follows the output example format while incorporating the key points from the provided context. Make sure to have at least three bullet points in each section. Add relevant sections as needed, but maintain the professional and engaging tone.\n",
    "Make sure to use today's date, {today_date}, in the subject line.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the chain with tracing\n",
    "chain = (newsletter_prompt | llm).with_config(\n",
    "    {\n",
    "        \"callbacks\": [tracer],\n",
    "        \"tags\": [\"newsletter_generation\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "newsletter = chain.invoke({\"context\": all_content, \"today_date\": get_current_date()})\n",
    "print(newsletter.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_message = newsletter_prompt.format(context=all_content, today_date=get_current_date())\n",
    "system_message = \"\"\"\n",
    "<SYSTEM MESSAGE>\n",
    "You are an expert newsletter creator. Your task is to generate a well-organized, engaging, and informative newsletter based on the articles and structure provided. The newsletter should follow the example format and maintain a consistent tone suitable for a [target audience] (e.g., tech enthusiasts, data scientists, etc.).\n",
    "\n",
    "- Keep the language professional and insightful.\n",
    "- Summarize articles clearly, highlighting key takeaways.\n",
    "- Include engaging headings and subheadings.\n",
    "- Ensure the content flows logically and is easy to read.\n",
    "\n",
    "Here's the structure to follow for each newsletter:\n",
    "\n",
    "1. **Introduction**: A brief overview of the newsletter's theme or main focus for the week. Provide 3 bullet points with key takeaways.\n",
    "2. **Main Section 1**: Headline for the first major topic, followed by a summary and analysis. Provide 3 bullet points with key takeaways.\n",
    "3. **Main Section 2**: Headline for the second major topic, followed by a summary and analysis. Provide 3 bullet points with key takeaways.\n",
    "4. **Additional Highlights**: Brief summaries of other important articles. Provide 3 bullet points with key takeaways.\n",
    "5. **Closing**: A call-to-action, final thought, or reminder to stay tuned for more content. Provide 3 bullet points with key takeaways.\n",
    "\n",
    "The articles and data you need for this week's edition are provided in the user prompt in the context.\n",
    "</SYSTEM MESSAGE>\n",
    "\"\"\"\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"today_date\"],\n",
    "    template= system_message + \"\"\"{context}\n",
    "\n",
    "Please generate the newsletter using the structure and style described in the system message. Ensure the language is engaging, and provide a concise summary of each article.\n",
    "Make sure to use today's date, {today_date}.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the chain with tracing\n",
    "chain = (newsletter_prompt | llm).with_config(\n",
    "    {\n",
    "        \"callbacks\": [tracer],\n",
    "        \"tags\": [\"newsletter_generation\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "newsletter = chain.invoke({\"context\": all_content, \"today_date\": get_current_date()})\n",
    "print(newsletter.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
