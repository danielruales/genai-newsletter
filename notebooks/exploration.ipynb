{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Access keys and configurations\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv('ANTHROPIC_API_KEY')\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY') # OpenAI API key\n",
    "os.environ[\"NOTION_API_KEY\"]=os.getenv('NOTION_API_KEY')\n",
    "os.environ[\"LIBRARY_DATABASE_ID\"]=os.getenv('LIBRARY_DATABASE_ID')\n",
    "os.environ[\"NEON_DATABASE_URL\"] = os.getenv(\"NEON_DATABASE_URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# engine = create_engine(NEON_DATABASE_URL)\n",
    "engine = create_engine(os.environ[\"NEON_DATABASE_URL\"])\n",
    "\n",
    "def run_neon_query(query):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vars = [\n",
    "    'LANGCHAIN_API_KEY',\n",
    "    'ANTHROPIC_API_KEY',\n",
    "    'LIBRARY_DATABASE_ID',\n",
    "    'NEON_DATABASE_URL'\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_vars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date():\n",
    "    # Get the current date\n",
    "    current_date = datetime.now()\n",
    "    # Format the date as YYYY-MM-DD\n",
    "    formatted_date = current_date.strftime('%Y-%m-%d')\n",
    "    return formatted_date\n",
    "\n",
    "print(get_current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langsmith import Client\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "\n",
    "# Initialize LangSmith client\n",
    "langsmith_client = Client()\n",
    "\n",
    "# Initialize LangSmith tracer\n",
    "tracer = LangChainTracer(project_name=os.getenv('LANGCHAIN_PROJECT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_model_costs(config_path=\"../config/model_costs.json\"):\n",
    "    try:\n",
    "        with open(Path(config_path)) as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Model costs file not found at {config_path}\")\n",
    "\n",
    "# Load the costs\n",
    "MODEL_COSTS = load_model_costs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "model_name = \"claude-3-5-sonnet-20241022\"\n",
    "llm = ChatAnthropic(\n",
    "    model=model_name,\n",
    "    max_tokens=4096,\n",
    "    temperature=0.3,\n",
    "    tags=[\"newsletter\"],\n",
    "    metadata={\n",
    "        \"ls_provider\": \"anthropic\",\n",
    "        \"ls_model_name\": model_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"model_cost_per_1k_input_tokens\": MODEL_COSTS[model_name][\"input\"],   # price per 1K input tokens\n",
    "        \"model_cost_per_1k_output_tokens\": MODEL_COSTS[model_name][\"output\"]    # price per 1K output tokens\n",
    "    }\n",
    ")\n",
    "\n",
    "# llm.invoke(\"Hello, world!\").content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_sql_query(filename):\n",
    "    query_path = Path(\"../queries\") / filename\n",
    "    with open(query_path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = load_sql_query(\"web_pages.sql\")\n",
    "df = run_neon_query(query)\n",
    "\n",
    "print(\"Number of rows:\", len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content_from_df(df):\n",
    "    \"\"\"Convert dataframe rows into formatted content string.\"\"\"\n",
    "    all_content = '<START CONTEXT>\\n'\n",
    "    all_content_list=[]\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Format each article with consistent structure\n",
    "        content = f\"\"\"\n",
    "<START Article Number: {idx + 1}>\n",
    "Title: {row['title']}\n",
    "URL: {row['url']}\n",
    "Summary: {row['summary']}\n",
    "Description: {row['description']}\n",
    "Created: {row['created_at'].strftime('%Y-%m-%d')}\n",
    "Type: {row['media_type']}\n",
    "<END Article Number: {idx + 1}>\n",
    "\"\"\"\n",
    "        # print('HERE***********', all_content_list)\n",
    "        all_content += content\n",
    "        all_content_list.append(content)\n",
    "    \n",
    "    all_content += '\\n<END CONTEXT>\\n--------------------\\n'\n",
    "    \n",
    "    return all_content, all_content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the results (summary, titles, etc.)\n",
    "all_content, all_content_list = create_content_from_df(df)\n",
    "\n",
    "print(len(all_content_list))\n",
    "print(all_content_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-shot example template\n",
    "NEWSLETTER_EXAMPLE = \"\"\"\n",
    "Subject: AI & Tech Weekly Summary {date}\n",
    "\n",
    "Welcome to this week's AI & Tech digest! Here's what's making waves:\n",
    "\n",
    "Featured Story #1: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies.\n",
    "Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Featured Story #2: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies.\n",
    "Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Featured Story #3: The Evolution of Large Language Models\n",
    "Last week's breakthrough in parameter-efficient training has opened new possibilities for smaller companies.\n",
    "Key highlights:\n",
    "• 40% reduction in training costs\n",
    "• Improved performance on specialized tasks\n",
    "• New benchmarks for model efficiency\n",
    "\n",
    "Industry Updates:\n",
    "• Google announced their latest quantum computing milestone\n",
    "• OpenAI released updates to their fine-tuning API\n",
    "• Meta's PyTorch 2.0 shows promising performance gains\n",
    "\n",
    "Key Takeaways:\n",
    "• The future of AI is in smaller, more efficient models\n",
    "• Quantum computing is making significant strides\n",
    "• Fine-tuning APIs are becoming more powerful\n",
    "\n",
    "Must-Read Resources:\n",
    "• New paper on efficient training methods [link]\n",
    "• Updated documentation for PyTorch 2.0 [link]\n",
    "• Comprehensive guide to quantum computing basics [link]\n",
    "\n",
    "Join us next week for more updates!\n",
    "-------------------\n",
    "\"\"\".format(date=get_current_date())\n",
    "\n",
    "newsletter_example_formatted = \"\"\"<OUTPUT EXAMPLE>\n",
    "{example}\n",
    "</OUTPUT EXAMPLE>\n",
    "\"\"\".format(example=NEWSLETTER_EXAMPLE)\n",
    "\n",
    "newsletter_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"today_date\"],\n",
    "    template= newsletter_example_formatted + \"\"\"{context}\n",
    "\n",
    "Generate today's newsletter that follows the output example format while incorporating the key points from the provided context. Make sure to have at least three bullet points in each section. Add relevant sections as needed, but maintain the professional and engaging tone.\n",
    "Make sure to use today's date, {today_date}, in the subject line.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the chain with tracing\n",
    "chain = (newsletter_prompt | llm).with_config(\n",
    "    {\n",
    "        \"callbacks\": [tracer],\n",
    "        \"tags\": [\"newsletter_generation\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "newsletter = chain.invoke({\"context\": all_content, \"today_date\": get_current_date()})\n",
    "print(newsletter.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
